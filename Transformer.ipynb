{"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13777,"status":"ok","timestamp":1644519300629,"user":{"displayName":"Vitalii Kyzym","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjiqCz_WLBhTLjA5JLio9WazXaOrL9-vEpz6Jd6=s64","userId":"15122577318140210742"},"user_tz":-60},"id":"sZOxG_4B5Nau","outputId":"483375f4-3418-4d99-9149-539d031dc0e8"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting en_core_web_sm==2.2.5\n","  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-2.2.5/en_core_web_sm-2.2.5.tar.gz (12.0 MB)\n","\u001b[K     |████████████████████████████████| 12.0 MB 6.9 MB/s \n","\u001b[?25hRequirement already satisfied: spacy>=2.2.2 in /usr/local/lib/python3.7/dist-packages (from en_core_web_sm==2.2.5) (2.2.4)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (4.62.3)\n","Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.19.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.6)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.0.6)\n","Requirement already satisfied: blis<0.5.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.4.1)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.6)\n","Requirement already satisfied: wasabi<1.1.0,>=0.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (0.9.0)\n","Requirement already satisfied: srsly<1.1.0,>=1.0.2 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.5)\n","Requirement already satisfied: catalogue<1.1.0,>=0.0.7 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.0.0)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (57.4.0)\n","Requirement already satisfied: plac<1.2.0,>=0.9.6 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (1.1.3)\n","Requirement already satisfied: thinc==7.4.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (7.4.0)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.7/dist-packages (from spacy>=2.2.2->en_core_web_sm==2.2.5) (2.23.0)\n","Requirement already satisfied: importlib-metadata>=0.20 in /usr/local/lib/python3.7/dist-packages (from catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (4.10.1)\n","Requirement already satisfied: typing-extensions>=3.6.4 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.10.0.2)\n","Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata>=0.20->catalogue<1.1.0,>=0.0.7->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.7.0)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (3.0.4)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2021.10.8)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3.0.0,>=2.13.0->spacy>=2.2.2->en_core_web_sm==2.2.5) (1.24.3)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the model via spacy.load('en_core_web_sm')\n","\u001b[38;5;2m✔ Linking successful\u001b[0m\n","/usr/local/lib/python3.7/dist-packages/en_core_web_sm -->\n","/usr/local/lib/python3.7/dist-packages/spacy/data/en\n","You can now load the model via spacy.load('en')\n"]}],"source":["!python -m spacy download en"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"xs1pEYPpqAMm"},"outputs":[],"source":["import os\n","import math\n","import time\n","from datetime import timedelta\n","import spacy\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import spacy\n","\n","import torchvision\n","from torchvision.transforms import ToTensor\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import DataLoader, Dataset\n","from torch.optim.lr_scheduler import ReduceLROnPlateau"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"jarAV0QP3jb7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644514352720,"user_tz":-60,"elapsed":239640,"user":{"displayName":"Vitalii Kyzym","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjiqCz_WLBhTLjA5JLio9WazXaOrL9-vEpz6Jd6=s64","userId":"15122577318140210742"}},"outputId":"ce76794b-638a-4b34-9caa-49df026fce77"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":1227,"status":"ok","timestamp":1644514353932,"user":{"displayName":"Vitalii Kyzym","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjiqCz_WLBhTLjA5JLio9WazXaOrL9-vEpz6Jd6=s64","userId":"15122577318140210742"},"user_tz":-60},"id":"xcWWils63pLO","outputId":"df400f6d-14b7-48ae-8b4e-a41965c342e9"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/My Drive/Personal/Projects/DepressionCounselorBot\n"]}],"source":["%cd \"/content/drive/My Drive/Personal/Projects/DepressionCounselorBot\""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mwy6istCpItn"},"outputs":[],"source":["spacy_eng = spacy.load(\"en\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bnOcGAvF6drT"},"outputs":[],"source":["class VocabularyEnglish:\n","    def __init__ (self, freq_threshold):\n","        self.itos = {0: \"<PAD>\", 1: \"<SOS>\", 2: \"<EOS>\", 3: \"<UNK >\"}\n","        self.stoi = {\"<PAD>\": 0, \"<SOS>\": 1, \"<EOS>\": 2, \"<UNK>\": 3}\n","        self.freq_threshold = freq_threshold\n","\n","    def __len__ (self):\n","        return len(self.itos)\n","\n","    @staticmethod\n","    def tokenizer_eng(text):\n","      return [tok.text.lower() for tok in spacy_eng.tokenizer(text)]\n","\n","    def build_vocabulary (self, sentence_list):\n","        idx = 4\n","        frequencies = {}\n","\n","        for sentence in sentence_list:\n","            for word in self.tokenizer_eng(sentence):\n","                if word not in frequencies:\n","                    frequencies[word] = 1\n","                else:\n","                    frequencies[word] += 1\n","\n","                    if frequencies[word] == self.freq_threshold:\n","                        self.stoi[word] = idx\n","                        self.itos[idx] = word\n","                        idx += 1\n","\n","    def numericalize (self, text):\n","        tokenized_text = self.tokenizer_eng(text)\n","\n","        return [\n","            self.stoi[token] if token in self.stoi else self.stoi[\"<UNK>\"] for token in tokenized_text    \n","        ]"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"L09FWkvn6tQX"},"outputs":[],"source":["class MentalHealthDataset(Dataset):\n","    def __init__(self, data_file_dir, transforms=None, freq_threshold=2):\n","        self.submission_comment_pairs = pd.read_csv(data_file_dir, lineterminator='\\n')\n","\n","        self.submissions = self.submission_comment_pairs[\"Submission\"]\n","        self.comments = self.submission_comment_pairs[\"Comment\"]\n","        self.full_pair = self.submissions + \" \" + self.comments\n","\n","        self.vocab_en = VocabularyEnglish(freq_threshold)\n","        self.vocab_en.build_vocabulary(self.full_pair.tolist())\n","\n","        self.transforms = transforms\n","\n","    def __len__ (self):\n","        return len(self.submission_comment_pairs)\n","\n","    def __getitem__ (self, idx):\n","        submission = self.submissions[idx]\n","        comment = self.comments[idx]\n","\n","        if self.transforms is not None:\n","            submission = self.transforms(submission)\n","            comment = self.transforms(comment)\n","\n","        numericalized_submission = [self.vocab_en.stoi[\"<SOS>\"]]\n","        numericalized_submission += self.vocab_en.numericalize(submission)\n","        numericalized_submission.append(self.vocab_en.stoi[\"<EOS>\"])\n","\n","        numericalized_comment = [self.vocab_en.stoi[\"<SOS>\"]]\n","        numericalized_comment += self.vocab_en.numericalize(comment)\n","        numericalized_comment.append(self.vocab_en.stoi[\"<EOS>\"])\n","\n","        return torch.tensor(numericalized_submission), torch.tensor(numericalized_comment)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"qynhYp906uad"},"outputs":[],"source":["class DataCollate:\n","    def __init__ (self, pad_idx):\n","      self.pad_idx = pad_idx\n","\n","    def __call__ (self, batch):\n","      submissions = [item[0] for item in batch]\n","      submissions = pad_sequence(submissions, batch_first=False, padding_value=self.pad_idx)\n","\n","      comments = [item[1] for item in batch]\n","      comments = pad_sequence(comments, batch_first=False, padding_value=self.pad_idx)\n","\n","      return submissions, comments"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"KYxTxH2L8fia"},"outputs":[],"source":["dataset = MentalHealthDataset(\"./clean_submission_comment_score_pairs_depression_help.csv\", transforms=None)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"TDKkV1xm7Xsd"},"outputs":[],"source":["batch_size = 32 # 128\n","src_vocab_size = len(dataset.vocab_en)\n","trg_vocab_size = src_vocab_size\n","src_pad_idx = dataset.vocab_en.stoi[\"<PAD>\"]\n","\n","num_workers = 8\n","pin_memory = True"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1644516569429,"user":{"displayName":"Vitalii Kyzym","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjiqCz_WLBhTLjA5JLio9WazXaOrL9-vEpz6Jd6=s64","userId":"15122577318140210742"},"user_tz":-60},"id":"M3R1dfC78qsb","outputId":"18717f0e-8b07-4f68-9cd9-fcbbd1c401fe"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]}],"source":["train_size = int(0.8 * len(dataset))\n","test_size = len(dataset) - train_size\n","\n","train_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, test_size])\n","train_dataloader = DataLoader(dataset=train_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True, pin_memory=pin_memory, collate_fn=DataCollate(pad_idx=src_pad_idx))\n","test_dataloader = DataLoader(dataset=test_dataset, batch_size=batch_size, num_workers=num_workers, shuffle=True, pin_memory=pin_memory, collate_fn=DataCollate(pad_idx=src_pad_idx))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"b6mvtEG9O_X5"},"outputs":[],"source":[""]},{"cell_type":"code","source":[""],"metadata":{"id":"8SLUo-3D2H40"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class PositionalEncoding(nn.Module):\n","    def __init__(self, d_model, dropout=0.1, max_len=5000):\n","        super(PositionalEncoding, self).__init__()\n","        self.dropout = nn.Dropout(p=dropout)\n","        self.scale = nn.Parameter(torch.ones(1))\n","\n","        pe = torch.zeros(max_len, d_model)\n","        position = torch.arange(0, max_len, dtype=torch.float).unsqueeze(1)\n","        div_term = torch.exp(torch.arange(\n","            0, d_model, 2).float() * (-math.log(10000.0) / d_model))\n","        pe[:, 0::2] = torch.sin(position * div_term)\n","        pe[:, 1::2] = torch.cos(position * div_term)\n","        pe = pe.unsqueeze(0).transpose(0, 1)\n","        self.register_buffer('pe', pe)\n","\n","    def forward(self, x):\n","        x = x + self.scale * self.pe[:x.size(0), :]\n","        return self.dropout(x)"],"metadata":{"id":"s28MJsHJhQr_"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class Transformer(nn.Module):\n","    def __init__(self, embedding_size, src_vocab_size, trg_vocab_size, src_pad_idx, num_heads, num_encoder_layers, num_decoder_layers, forward_expansion, dropout, max_len, device):\n","        super(Transformer, self).__init__()\n","\n","        self.embedding_size = embedding_size\n","\n","        self.src_word_embedding = nn.Embedding(src_vocab_size, embedding_size)\n","        self.trg_word_embedding = nn.Embedding(trg_vocab_size, embedding_size)\n","\n","        self.src_positional_encoding = PositionalEncoding(embedding_size, dropout, max_len)\n","        self.trg_positional_encoding = PositionalEncoding(embedding_size, dropout, max_len)\n","\n","        self.device = device\n","        self.transformer = nn.Transformer(\n","            embedding_size,\n","            num_heads,\n","            num_encoder_layers,\n","            num_decoder_layers,\n","            forward_expansion,\n","            dropout,\n","        )\n","        self.fc = nn.Linear(embedding_size, trg_vocab_size)\n","        self.dropout = nn.Dropout(dropout)\n","        self.src_pad_idx = src_pad_idx\n","\n","    def make_src_mask(self, src):\n","        src_mask = src.transpose(0, 1) == self.src_pad_idx\n","\n","        # (N, src_len)\n","        return src_mask.to(self.device)\n","\n","    def forward(self, src, trg):\n","        src_seq_length, N = src.shape\n","        trg_seq_length, N = trg.shape\n","\n","        src_embedding = self.src_positional_encoding(self.src_word_embedding(src))\n","        trg_embedding = self.trg_positional_encoding(self.trg_word_embedding(trg))\n","\n","        src_padding_mask = self.make_src_mask(src)\n","        trg_padding_mask = self.make_src_mask(trg)\n","        trg_no_peak_mask = self.transformer.generate_square_subsequent_mask(trg_seq_length)\n","\n","        out = self.transformer(\n","            src_embedding,\n","            trg_embedding,\n","            src_key_padding_mask=src_padding_mask,\n","            tgt_key_padding_mask=trg_padding_mask,\n","            tgt_mask=trg_no_peak_mask,\n","        )\n","        \n","        out = self.fc(out)\n","        \n","        return out"],"metadata":{"id":"sFBuHe5xlQV8"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5s22N9mB9QGq"},"outputs":[],"source":["def save_checkpoint(state, filename=\"checkpoint.pth.tar\"):\n","    print(\"Saving checkpoint\")\n","    torch.save(state, filename)\n","\n","def load_checkpoint(checkpoint, model, optimizer):\n","    print(\"Loading checkpoint\")\n","    model.load_state_dict(checkpoint[\"state_dict\"])\n","    optimizer.load_state_dict(checkpoint[\"optimizer\"])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"r9s8Qbh89h_h"},"outputs":[],"source":["def generate_comment(model, sentence, device, max_length=50):\n","\n","    if type(sentence) == str:\n","        tokens = [token.text.lower() for token in spacy_eng(sentence)]\n","    else:\n","        tokens = [token.lower() for token in sentence]\n","\n","    tokens.insert(0, \"<SOS>\")\n","    tokens.append(\"<EOS>\")\n","\n","    text_to_indices = [dataset.vocab_en.stoi[token] for token in tokens]\n","\n","    sentence_tensor = torch.LongTensor(text_to_indices).unsqueeze(1).to(device)\n","\n","    outputs = [dataset.vocab_en.stoi[\"<SOS>\"]]\n","\n","    for i in range(max_length):\n","        trg_tensor = torch.LongTensor(outputs).unsqueeze(1).to(device)\n","\n","        with torch.no_grad():\n","            output = model(sentence_tensor, trg_tensor)\n","\n","        best_guess = output.argmax(2)[-1, :].item()\n","        outputs.append(best_guess)\n","\n","        if best_guess == dataset.vocab_en.stoi[\"<EOS>\"]:\n","            break\n","\n","    translated_sentence = [dataset.vocab_en.itos[idx] for idx in outputs]\n","\n","    return translated_sentence[1:]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"C0U4DyTgndOa"},"outputs":[],"source":[""]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3t1gNBK4nk7j"},"outputs":[],"source":["# We're ready to define everything we need for training our Seq2Seq model\n","device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n","\n","load_model = False\n","save_model = True\n","\n","# Training hyperparameters\n","num_epochs = 10000\n","learning_rate = 3e-4\n","\n","# Model hyperparameters\n","embedding_size = 512\n","num_heads = 8\n","num_encoder_layers = 3\n","num_decoder_layers = 3\n","dropout = 0.10\n","max_len = 150\n","forward_expansion = 4\n","\n","\n","\n","model = Transformer(\n","    embedding_size,\n","    src_vocab_size,\n","    trg_vocab_size,\n","    src_pad_idx,\n","    num_heads,\n","    num_encoder_layers,\n","    num_decoder_layers,\n","    forward_expansion,\n","    dropout,\n","    max_len,\n","    device,\n",").to(device)\n","\n","optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n","\n","scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n","    optimizer, factor=0.1, patience=10, verbose=True\n",")\n","\n","pad_idx = dataset.vocab_en.stoi[\"<PAD>\"]\n","criterion = nn.CrossEntropyLoss(ignore_index=pad_idx)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ydzk8HUWnrE6"},"outputs":[],"source":["# if load_model:\n","#     load_checkpoint(torch.load(\"my_checkpoint.pth.tar\"), model, optimizer)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dHQXJl0Gn3fG"},"outputs":[],"source":["def epoch_train():\n","  model.train()\n","  losses = []\n","\n","  for batch_idx, (inp_data, target) in enumerate(train_dataloader):\n","\n","    # Get input and targets and get to cuda\n","    inp_data = inp_data.to(device)\n","    target = target.to(device)\n","\n","    # Forward prop\n","    output = model(inp_data, target[:-1, :])\n","\n","    # Output is of shape (trg_len, batch_size, output_dim) but Cross Entropy Loss\n","    # doesn't take input in that form. For example if we have MNIST we want to have\n","    # output to be: (N, 10) and targets just (N). Here we can view it in a similar\n","    # way that we have output_words * batch_size that we want to send in into\n","    # our cost function, so we need to do some reshapin.\n","    # Let's also remove the start token while we're at it\n","    output = output.reshape(-1, output.shape[2])\n","    target = target[1:].reshape(-1)\n","\n","    optimizer.zero_grad()\n","\n","    loss = criterion(output, target)\n","    losses.append(loss.item())\n","\n","    # Back prop\n","    loss.backward()\n","    # Clip to avoid exploding gradient issues, makes sure grads are\n","    # within a healthy range\n","    torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1)\n","\n","    # Gradient descent step\n","    optimizer.step()\n","\n","    # plot to tensorboard\n","    # writer.add_scalar(\"Training loss\", loss, global_step=step)\n","    # step += 1\n","  return sum(losses) / len(losses)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hZ2x6d9JoTlX"},"outputs":[],"source":["def epoch_test():\n","  model.eval()\n","  losses = []\n","\n","  for batch_idx, (inp_data, target) in enumerate(test_dataloader):\n","    with torch.no_grad():\n","\n","      # Get input and targets and get to cuda\n","      inp_data = inp_data.to(device)\n","      target = target.to(device)\n","\n","      # Forward prop\n","      output = model(inp_data, target[:-1, :])\n","\n","      # Output is of shape (trg_len, batch_size, output_dim) but Cross Entropy Loss\n","      # doesn't take input in that form. For example if we have MNIST we want to have\n","      # output to be: (N, 10) and targets just (N). Here we can view it in a similar\n","      # way that we have output_words * batch_size that we want to send in into\n","      # our cost function, so we need to do some reshapin.\n","      # Let's also remove the start token while we're at it\n","      output = output.reshape(-1, output.shape[2])\n","      target = target[1:].reshape(-1)\n","\n","      loss = criterion(output, target)\n","      losses.append(loss.item())\n","\n","\n","  return sum(losses) / len(losses)"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":1000},"id":"ELYZD26CuDII","outputId":"35450039-11b4-4a25-b744-a0f6c46f7f95","executionInfo":{"status":"error","timestamp":1644519180088,"user_tz":-60,"elapsed":1713573,"user":{"displayName":"Vitalii Kyzym","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjiqCz_WLBhTLjA5JLio9WazXaOrL9-vEpz6Jd6=s64","userId":"15122577318140210742"}}},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Saving checkpoint\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/torch/utils/data/dataloader.py:481: UserWarning: This DataLoader will create 8 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n","  cpuset_checked))\n"]},{"output_type":"stream","name":"stdout","text":["Translated example sentence: \n"," ['you', 'you', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.', '.']\n","Epoch 0 Train Loss: 5.726942675454276 Test Loss: 5.794261693954468 LR:0.0003 Time: 00:01:52.039682\n","Saving checkpoint\n","Translated example sentence: \n"," ['i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i', 'i']\n","Epoch 1 Train Loss: 5.692608946845645 Test Loss: 5.794719457626343 LR:0.0003 Time: 00:01:50.859410\n","Saving checkpoint\n","Translated example sentence: \n"," ['i', 'm', 'm', 'm', 'm', 'the', 'm', 'the', 'm', 'the', 'm', 'the', 'm', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'the', 'i', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm', 'm']\n","Epoch 2 Train Loss: 5.587553750900995 Test Loss: 5.596720218658447 LR:0.0003 Time: 00:01:49.982054\n","Saving checkpoint\n","Translated example sentence: \n"," ['i', 'm', 'sorry', 'to', 'the', 'same', 'to', 'the', 'same', 'to', 'the', 'same', '.', 'i', 'm', 'not', 'the', 'same', '.', 'i', 'm', 'not', 'the', 'same', 'to', 'the', 'same', 'to', 'the', 'same', '.', 'i', 'm', 'the', 'same', 'to', 'the', 'same', '.', '<EOS>']\n","Epoch 3 Train Loss: 5.32840971719651 Test Loss: 5.498634576797485 LR:0.0003 Time: 00:01:50.175683\n","Saving checkpoint\n","Translated example sentence: \n"," ['i', 'm', 'sorry', '.', 'i', 'm', 'not', 'a', 'lot', '.', '<EOS>']\n","Epoch 4 Train Loss: 5.043825876145136 Test Loss: 5.302654266357422 LR:0.0003 Time: 00:01:48.030290\n","Saving checkpoint\n","Translated example sentence: \n"," ['i', 'm', 'sorry', 'to', 'help', '.', '<EOS>']\n","Epoch 5 Train Loss: 4.7565415019080755 Test Loss: 5.221600770950317 LR:0.0003 Time: 00:01:48.330482\n","Saving checkpoint\n","Translated example sentence: \n"," ['i', 'm', 'sorry', 'to', 'help', '.', '<EOS>']\n","Epoch 6 Train Loss: 4.511737255823045 Test Loss: 5.232382853825887 LR:0.0003 Time: 00:01:48.288719\n","Saving checkpoint\n","Translated example sentence: \n"," ['i', 'm', 'sorry', 'to', 'help', '.', '<EOS>']\n","Epoch 7 Train Loss: 4.269754648208618 Test Loss: 5.109795808792114 LR:0.0003 Time: 00:01:50.083464\n","Saving checkpoint\n","Translated example sentence: \n"," ['i', 'm', 'sorry', 'to', 'hear', 'you', 'are', 'not', 'alone', '.', 'i', 'm', 'not', 'sure', 'you', 'are', 'not', 'alone', '.', '<EOS>']\n","Epoch 8 Train Loss: 4.064417600631714 Test Loss: 5.247943878173828 LR:0.0003 Time: 00:01:50.052808\n","Saving checkpoint\n","Translated example sentence: \n"," ['i', 'm', 'sorry', 'you', 'are', 'not', 'alone', '.', 'i', 'm', 'not', 'alone', '.', '<EOS>']\n","Epoch 9 Train Loss: 3.849358252116612 Test Loss: 5.149812777837117 LR:0.0003 Time: 00:01:49.879633\n","Saving checkpoint\n","Translated example sentence: \n"," ['i', 'm', 'sorry', 'to', 'hear', 'you', 'are', 'not', 'alone', '.', 'i', 'm', 'not', 'alone', '.', '<EOS>']\n","Epoch 10 Train Loss: 3.657276471455892 Test Loss: 5.160695234934489 LR:0.0003 Time: 00:01:49.830210\n","Saving checkpoint\n","Translated example sentence: \n"," ['i', 'm', 'sorry', 'to', 'hear', 'you', 'are', 'not', 'alone', '.', 'i', 'm', 'not', 'alone', '.', 'if', 'you', 'are', 'not', 'alone', '.', 'if', 'you', 'are', 'not', 'alone', '.', 'i', 'm', 'not', 'alone', '.', '<EOS>']\n","Epoch 11 Train Loss: 3.4446458248865035 Test Loss: 5.266843318939209 LR:0.0003 Time: 00:01:50.501282\n","Saving checkpoint\n","Translated example sentence: \n"," ['i', 'm', 'sorry', 'to', 'hear', 'you', 'are', 'not', 'alone', '.', 'if', 'you', 'are', 'not', 'alone', '.', 'if', 'you', 'are', 'not', 'alone', '.', '<EOS>']\n","Epoch 12 Train Loss: 3.254293271473476 Test Loss: 5.283361752827962 LR:0.0003 Time: 00:01:49.877964\n","Saving checkpoint\n","Translated example sentence: \n"," ['i', 'm', 'sorry', 'to', 'hear', 'you', 'are', 'not', 'alone', '.', 'if', 'you', 'are', 'not', 'alone', '.', 'if', 'you', 'are', 'not', 'alone', '.', 'if', 'you', 'are', 'not', 'alone', '.', '<EOS>']\n","Epoch 13 Train Loss: 3.0650412014552524 Test Loss: 5.321847120920817 LR:0.0003 Time: 00:01:51.124312\n","Saving checkpoint\n","Translated example sentence: \n"," ['i', 'm', 'sorry', 'to', 'hear', 'you', 'are', 'not', 'alone', '.', 'if', 'you', 'are', 'not', 'alone', '.', 'if', 'you', 'are', 'not', 'alone', '.', 'if', 'you', 'are', 'not', 'alone', '.', 'if', 'you', 'are', 'not', 'alone', '.', '<EOS>']\n","Epoch 14 Train Loss: 2.8764495849609375 Test Loss: 5.3494791984558105 LR:0.0003 Time: 00:01:50.873918\n","Saving checkpoint\n","Translated example sentence: \n"," ['i', 'm', 'sorry', 'to', 'hear', 'you', 'are', 'not', 'alone', '.', 'but', 'i', 'm', 'not', 'alone', '.', 'if', 'you', 'are', 'not', 'alone', '.', 'if', 'you', 'are', 'not', 'alone', '.', 'if', 'you', 'are', 'not', 'alone', '.', '<EOS>']\n","Epoch 15 Train Loss: 2.693956216176351 Test Loss: 5.399748007456462 LR:0.0003 Time: 00:01:51.003098\n","Saving checkpoint\n","Translated example sentence: \n"," ['i', 'm', 'sorry', 'to', 'hear', 'that', 'you', 'are', 'not', 'alone', '.', 'but', 'if', 'you', 'are', 'not', 'alone', '.', 'but', 'if', 'you', 'are', 'not', 'alone', '.', 'but', 'if', 'you', 'are', 'not', 'are', 'not', 'are', 'not', 'alone', '.', '<EOS>']\n","Epoch 16 Train Loss: 2.5132837409064885 Test Loss: 5.527853727340698 LR:0.0003 Time: 00:01:51.555842\n","Saving checkpoint\n"]},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-66-c72b5293dac2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0msave_checkpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m   \u001b[0mmean_train_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_train\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m   \u001b[0mmean_test_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mepoch_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-63-16e387fac462>\u001b[0m in \u001b[0;36mepoch_train\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m# Back prop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0;31m# Clip to avoid exploding gradient issues, makes sure grads are\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m# within a healthy range\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    305\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    306\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 307\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    308\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    154\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    155\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 156\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    158\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}],"source":["# train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n","#     (train_data, valid_data, test_data),\n","#     batch_size=batch_size,\n","#     sort_within_batch=True,\n","#     sort_key=lambda x: len(x.src),\n","#     device=device,\n","# )\n","\n","sentence = \"Struggling to cope. I just wish I had the power to change everything.\"\n","train_loss_hist = []\n","test_loss_hist = []\n","\n","for epoch in range(num_epochs):\n","  start_time = time.time()\n","\n","  if save_model:\n","    checkpoint = {\n","        \"state_dict\": model.state_dict(),\n","        \"optimizer\": optimizer.state_dict(),\n","    }\n","    save_checkpoint(checkpoint)\n","\n","  mean_train_loss = epoch_train()\n","  \n","  mean_test_loss = epoch_test()\n","\n","  translated_sentence = generate_comment(\n","    model, sentence, device, max_length=50\n","  )\n","  print(f\"Translated example sentence: \\n {translated_sentence}\")\n","\n","  train_loss_hist.append(mean_train_loss)\n","  test_loss_hist.append(mean_test_loss)    \n","\n","  scheduler.step(mean_train_loss)\n","\n","  elapsed_time = time.time() - start_time\n","  curr_lr = optimizer.param_groups[0]['lr']\n","  print(f'Epoch {epoch} Train Loss: {mean_train_loss} Test Loss: {mean_test_loss} LR:{curr_lr} Time: {time.strftime(\"%H:%M:%S.{}\".format(str(elapsed_time % 1)[2:])[:15], time.gmtime(elapsed_time))}')\n","\n","\n","# running on entire test data takes a while\n","# score = bleu(test_data[1:100], model, german, english, device)\n","# print(f\"Bleu score {score * 100:.2f}\")"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ijs03kai8SR2"},"outputs":[],"source":["m/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"H39jdz2S-08q"},"outputs":[],"source":[""]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Transformer.ipynb","provenance":[],"authorship_tag":"ABX9TyPkTgflu3K6nFqLLOt4lUQ5"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}